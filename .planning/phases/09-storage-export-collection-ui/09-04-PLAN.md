---
phase: 09-storage-export-collection-ui
plan: 04
type: execute
wave: 3
depends_on: ["09-03"]
files_modified:
  - apps/api/pyproject.toml
  - apps/api/src/app/services/scheduler.py
  - apps/api/src/app/routers/collection.py
  - apps/api/src/app/models.py
  - apps/api/src/app/background.py
  - apps/api/src/app/main.py
  - apps/api/migrations/042_collection_schedules.sql
autonomous: true
user_setup: []

must_haves:
  truths:
    - "APScheduler starts on API startup"
    - "Schedules persist in database and reload on restart"
    - "Schedule CRUD endpoints validate cron expressions"
    - "Scheduled collection runs automatically at configured time"
    - "Scheduled runs are skipped if a collection is already running"
  artifacts:
    - path: "apps/api/src/app/services/scheduler.py"
      provides: "APScheduler integration"
      contains: "AsyncIOScheduler"
    - path: "apps/api/src/app/routers/collection.py"
      provides: "Schedule CRUD endpoints"
      exports: ["get_schedule", "update_schedule"]
    - path: "apps/api/migrations/042_collection_schedules.sql"
      provides: "collection_schedules table"
      contains: "CREATE TABLE collection_schedules"
  key_links:
    - from: "apps/api/src/app/main.py"
      to: "apps/api/src/app/services/scheduler.py"
      via: "lifespan startup"
      pattern: "scheduler.start"
    - from: "apps/api/src/app/services/scheduler.py"
      to: "apps/api/src/app/services/collection.py"
      via: "run_scheduled_collection function"
      pattern: "CollectionService"
---

<objective>
Implement backend scheduler infrastructure for cron-based scheduled collection runs using APScheduler, with database persistence and CRUD endpoints.

Purpose: Foundation for automated monthly collection runs. Schedules persist across API restarts.

Output: APScheduler service, schedule CRUD endpoints, database migration, lifecycle integration.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/09-storage-export-collection-ui/09-CONTEXT.md
@.planning/phases/09-storage-export-collection-ui/09-RESEARCH.md

@apps/api/src/app/main.py
@apps/api/src/app/background.py
@apps/api/src/app/routers/collection.py
@apps/api/src/app/services/collection.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add APScheduler dependencies and create scheduler service</name>
  <files>apps/api/pyproject.toml, apps/api/src/app/services/scheduler.py</files>
  <action>
1. Add dependencies to pyproject.toml in the [project] dependencies array:
```toml
"apscheduler>=3.10.0,<4.0.0",
"croniter>=2.0.0,<3.0.0",
```

2. Create new file apps/api/src/app/services/scheduler.py:

```python
"""
Scheduler service for cron-based collection runs.

Uses APScheduler with AsyncIOScheduler for non-blocking scheduled tasks.
Schedules persist in database and are loaded on startup.
"""

import logging
from datetime import datetime, timezone

from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.cron import CronTrigger
from croniter import croniter

from app.database import get_supabase

logger = logging.getLogger(__name__)

# Global scheduler instance
scheduler = AsyncIOScheduler(timezone="UTC")


def validate_cron(expression: str) -> bool:
    """Validate a cron expression."""
    try:
        croniter(expression)
        return True
    except (KeyError, ValueError):
        return False


async def run_scheduled_collection(org_id: str, preset_id: str, schedule_id: str):
    """
    Execute a scheduled collection run.

    Checks for active runs first and queues if one is running.
    """
    from app.services.collection import CollectionService

    supabase = get_supabase()
    service = CollectionService(supabase)

    logger.info(f"Starting scheduled collection for org {org_id}, preset {preset_id}")

    # Check for active runs
    active_runs = (
        supabase.table("collection_runs")
        .select("id", count="exact")
        .eq("org_id", org_id)
        .in_("status", ["pending", "running", "paused"])
        .execute()
    )

    if (active_runs.count or 0) > 0:
        logger.info(f"Collection already running for org {org_id}, skipping scheduled run")
        # Could queue for later, but for now just skip
        return

    # Get preset category IDs
    preset_result = (
        supabase.table("amazon_category_presets")
        .select("category_ids")
        .eq("id", preset_id)
        .eq("org_id", org_id)
        .execute()
    )

    if not preset_result.data:
        logger.error(f"Preset {preset_id} not found for org {org_id}")
        return

    category_ids = preset_result.data[0]["category_ids"]
    if not category_ids:
        logger.warning(f"Preset {preset_id} has no categories, skipping")
        return

    # Create and start the run
    result = await service.create_run(
        org_id=org_id,
        user_id="system",  # System-initiated run
        category_ids=category_ids,
        name=f"Scheduled Run {datetime.now(timezone.utc).strftime('%Y-%m-%d')}",
    )

    if "error" in result:
        logger.error(f"Failed to create scheduled run: {result['message']}")
        return

    run = result["run"]
    run_id = run["id"]

    # Start the run
    await service.start_run(run_id, org_id)

    # Execute the collection pipeline
    # Phase 1: Amazon
    amazon_result = await service.run_amazon_collection(
        run_id=run_id,
        org_id=org_id,
        category_ids=category_ids,
    )

    if amazon_result.get("status") in ("failed", "paused"):
        return

    # Phase 2: eBay
    await service.run_ebay_seller_search(run_id=run_id, org_id=org_id)

    logger.info(f"Scheduled collection completed for org {org_id}")


async def load_schedules():
    """Load all enabled schedules from database and add to scheduler."""
    supabase = get_supabase()

    result = (
        supabase.table("collection_schedules")
        .select("id, org_id, preset_id, cron_expression")
        .eq("enabled", True)
        .execute()
    )

    for schedule in result.data or []:
        try:
            trigger = CronTrigger.from_crontab(schedule["cron_expression"])
            scheduler.add_job(
                run_scheduled_collection,
                trigger,
                args=[schedule["org_id"], schedule["preset_id"], schedule["id"]],
                id=f"collection_{schedule['id']}",
                replace_existing=True,
                misfire_grace_time=3600,  # 1 hour grace for missed runs
            )
            logger.info(f"Loaded schedule {schedule['id']} for org {schedule['org_id']}")
        except Exception as e:
            logger.error(f"Failed to load schedule {schedule['id']}: {e}")


def add_schedule(schedule_id: str, org_id: str, preset_id: str, cron_expression: str):
    """Add a schedule to the scheduler."""
    try:
        trigger = CronTrigger.from_crontab(cron_expression)
        scheduler.add_job(
            run_scheduled_collection,
            trigger,
            args=[org_id, preset_id, schedule_id],
            id=f"collection_{schedule_id}",
            replace_existing=True,
            misfire_grace_time=3600,
        )
        logger.info(f"Added schedule {schedule_id}")
    except Exception as e:
        logger.error(f"Failed to add schedule {schedule_id}: {e}")
        raise


def remove_schedule(schedule_id: str):
    """Remove a schedule from the scheduler."""
    job_id = f"collection_{schedule_id}"
    if scheduler.get_job(job_id):
        scheduler.remove_job(job_id)
        logger.info(f"Removed schedule {schedule_id}")


def get_next_run_time(schedule_id: str) -> datetime | None:
    """Get the next scheduled run time for a schedule."""
    job_id = f"collection_{schedule_id}"
    job = scheduler.get_job(job_id)
    return job.next_run_time if job else None
```
  </action>
  <verify>
1. apps/api/pyproject.toml contains apscheduler and croniter in dependencies
2. apps/api/src/app/services/scheduler.py exists with AsyncIOScheduler and validate_cron function
  </verify>
  <done>
- APScheduler and croniter dependencies added to pyproject.toml
- scheduler.py service created with load_schedules, add_schedule, remove_schedule functions
- run_scheduled_collection checks for active runs before starting
  </done>
</task>

<task type="auto">
  <name>Task 2: Create database migration for collection_schedules</name>
  <files>apps/api/migrations/042_collection_schedules.sql</files>
  <action>
Create migration file:

```sql
-- Migration: 042_collection_schedules.sql
-- Collection schedule configuration for cron-based automated runs

-- Collection schedules table (one per org for now)
CREATE TABLE IF NOT EXISTS collection_schedules (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    org_id UUID NOT NULL REFERENCES organizations(id) ON DELETE CASCADE,
    preset_id UUID REFERENCES amazon_category_presets(id) ON DELETE SET NULL,
    cron_expression TEXT NOT NULL DEFAULT '0 0 1 * *',  -- Default: 1st of month at midnight UTC
    enabled BOOLEAN NOT NULL DEFAULT false,
    notify_email BOOLEAN NOT NULL DEFAULT false,
    last_run_at TIMESTAMPTZ,
    next_run_at TIMESTAMPTZ,
    created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
    UNIQUE(org_id)  -- One schedule per org for simplicity
);

-- Index for loading enabled schedules
CREATE INDEX IF NOT EXISTS idx_collection_schedules_enabled
ON collection_schedules(enabled) WHERE enabled = true;

-- RLS policies
ALTER TABLE collection_schedules ENABLE ROW LEVEL SECURITY;

-- Admin can manage their org's schedule
CREATE POLICY "admin_manage_schedule" ON collection_schedules
    FOR ALL
    USING (
        EXISTS (
            SELECT 1 FROM memberships m
            WHERE m.org_id = collection_schedules.org_id
            AND m.user_id = auth.uid()
            AND m.role = 'admin'
        )
    );

-- Comment
COMMENT ON TABLE collection_schedules IS 'Cron-based schedule configuration for automated collection runs';
```
  </action>
  <verify>File exists at apps/api/migrations/042_collection_schedules.sql with CREATE TABLE collection_schedules</verify>
  <done>Migration creates collection_schedules table with cron_expression, enabled, preset_id columns and RLS</done>
</task>

<task type="auto">
  <name>Task 3: Add schedule CRUD endpoints and models</name>
  <files>apps/api/src/app/routers/collection.py, apps/api/src/app/models.py</files>
  <action>
1. Add models to models.py after the existing collection models:

```python
# ============================================================
# Collection Schedule Models
# ============================================================


class CollectionScheduleResponse(BaseModel):
    """Collection schedule configuration."""

    id: Optional[str] = None
    preset_id: Optional[str] = None
    preset_name: Optional[str] = None
    cron_expression: str
    enabled: bool
    notify_email: bool
    last_run_at: Optional[datetime] = None
    next_run_at: Optional[datetime] = None


class CollectionScheduleUpdate(BaseModel):
    """Update collection schedule."""

    preset_id: Optional[str] = None
    cron_expression: Optional[str] = None
    enabled: Optional[bool] = None
    notify_email: Optional[bool] = None
```

2. Add endpoints to collection.py after the template endpoints:

```python
from app.services.scheduler import (
    validate_cron,
    add_schedule,
    remove_schedule,
    get_next_run_time,
)
from app.models import (
    # ... existing imports ...
    CollectionScheduleResponse,
    CollectionScheduleUpdate,
)

# ============================================================
# Schedule Endpoints
# ============================================================


@router.get("/schedule", response_model=CollectionScheduleResponse)
async def get_schedule(
    user: dict = Depends(require_permission_key("admin.automation")),
    service: CollectionService = Depends(get_collection_service),
):
    """
    Get collection schedule for the organization.

    Returns current schedule configuration or defaults if none exists.

    Requires admin.automation permission.
    """
    org_id = user["membership"]["org_id"]
    supabase = get_supabase()

    # Get schedule with preset name join
    result = (
        supabase.table("collection_schedules")
        .select("*, amazon_category_presets(name)")
        .eq("org_id", org_id)
        .execute()
    )

    if not result.data:
        # Return defaults (no schedule configured)
        return CollectionScheduleResponse(
            cron_expression="0 0 1 * *",  # 1st of month at midnight
            enabled=False,
            notify_email=False,
        )

    schedule = result.data[0]
    preset_data = schedule.get("amazon_category_presets")

    # Get next run time from scheduler
    next_run = get_next_run_time(schedule["id"]) if schedule.get("enabled") else None

    return CollectionScheduleResponse(
        id=schedule["id"],
        preset_id=schedule.get("preset_id"),
        preset_name=preset_data["name"] if preset_data else None,
        cron_expression=schedule["cron_expression"],
        enabled=schedule["enabled"],
        notify_email=schedule["notify_email"],
        last_run_at=schedule.get("last_run_at"),
        next_run_at=next_run.isoformat() if next_run else None,
    )


@router.patch("/schedule", response_model=CollectionScheduleResponse)
async def update_schedule(
    body: CollectionScheduleUpdate,
    user: dict = Depends(require_permission_key("admin.automation")),
    service: CollectionService = Depends(get_collection_service),
):
    """
    Update collection schedule.

    Creates schedule if none exists. Validates cron expression.

    Requires admin.automation permission.
    """
    org_id = user["membership"]["org_id"]
    supabase = get_supabase()

    # Validate cron if provided
    if body.cron_expression and not validate_cron(body.cron_expression):
        raise HTTPException(status_code=400, detail="Invalid cron expression")

    # Check if schedule exists
    existing = (
        supabase.table("collection_schedules")
        .select("id")
        .eq("org_id", org_id)
        .execute()
    )

    update_data = body.model_dump(exclude_unset=True)
    update_data["updated_at"] = datetime.now(timezone.utc).isoformat()

    if existing.data:
        # Update existing
        schedule_id = existing.data[0]["id"]
        result = (
            supabase.table("collection_schedules")
            .update(update_data)
            .eq("id", schedule_id)
            .execute()
        )
        schedule = result.data[0]

        # Update scheduler
        if schedule["enabled"] and schedule.get("preset_id"):
            add_schedule(
                schedule_id,
                org_id,
                schedule["preset_id"],
                schedule["cron_expression"],
            )
        else:
            remove_schedule(schedule_id)
    else:
        # Create new
        insert_data = {
            "org_id": org_id,
            "cron_expression": body.cron_expression or "0 0 1 * *",
            "preset_id": body.preset_id,
            "enabled": body.enabled or False,
            "notify_email": body.notify_email or False,
        }
        result = (
            supabase.table("collection_schedules")
            .insert(insert_data)
            .execute()
        )
        schedule = result.data[0]

        # Add to scheduler if enabled
        if schedule["enabled"] and schedule.get("preset_id"):
            add_schedule(
                schedule["id"],
                org_id,
                schedule["preset_id"],
                schedule["cron_expression"],
            )

    # Get preset name
    preset_name = None
    if schedule.get("preset_id"):
        preset_result = (
            supabase.table("amazon_category_presets")
            .select("name")
            .eq("id", schedule["preset_id"])
            .execute()
        )
        if preset_result.data:
            preset_name = preset_result.data[0]["name"]

    # Get next run time
    next_run = get_next_run_time(schedule["id"]) if schedule.get("enabled") else None

    return CollectionScheduleResponse(
        id=schedule["id"],
        preset_id=schedule.get("preset_id"),
        preset_name=preset_name,
        cron_expression=schedule["cron_expression"],
        enabled=schedule["enabled"],
        notify_email=schedule["notify_email"],
        last_run_at=schedule.get("last_run_at"),
        next_run_at=next_run.isoformat() if next_run else None,
    )
```

Add necessary imports at top:
```python
from datetime import datetime, timezone
from app.database import get_supabase
```
  </action>
  <verify>
1. collection.py has get_schedule and update_schedule endpoints
2. models.py has CollectionScheduleResponse and CollectionScheduleUpdate classes
  </verify>
  <done>
- GET /collection/schedule returns current schedule or defaults
- PATCH /collection/schedule creates or updates schedule
- Cron validation before saving
- Scheduler updated when enabled/disabled
  </done>
</task>

<task type="auto">
  <name>Task 4: Integrate scheduler into application lifecycle</name>
  <files>apps/api/src/app/background.py, apps/api/src/app/main.py</files>
  <action>
1. Update background.py to add scheduler startup function:

Add after the existing collection_startup_recovery function:

```python
async def scheduler_startup():
    """
    Start the APScheduler and load schedules from database.

    Called during application startup.
    """
    try:
        from app.services.scheduler import scheduler, load_schedules

        # Start scheduler
        scheduler.start()
        logger.info("APScheduler started")

        # Load schedules from database
        await load_schedules()
    except Exception as e:
        logger.error(f"Scheduler startup failed: {e}")


def scheduler_shutdown():
    """
    Shutdown the APScheduler gracefully.

    Called during application shutdown.
    """
    try:
        from app.services.scheduler import scheduler

        scheduler.shutdown(wait=False)
        logger.info("APScheduler shutdown")
    except Exception as e:
        logger.error(f"Scheduler shutdown failed: {e}")
```

2. Update main.py lifespan to include scheduler:

```python
from app.background import (
    cleanup_worker,
    collection_startup_recovery,
    scheduler_startup,
    scheduler_shutdown,
)

@asynccontextmanager
async def lifespan(app: FastAPI):
    """Manage application lifecycle - start/stop background tasks."""
    global _cleanup_task
    # Startup
    _cleanup_task = asyncio.create_task(cleanup_worker())

    # Check for interrupted collection runs
    await collection_startup_recovery()

    # Start scheduler and load schedules
    await scheduler_startup()

    yield

    # Shutdown
    scheduler_shutdown()

    if _cleanup_task:
        _cleanup_task.cancel()
        try:
            await _cleanup_task
        except asyncio.CancelledError:
            pass
```
  </action>
  <verify>
1. background.py has scheduler_startup and scheduler_shutdown functions
2. main.py lifespan calls scheduler_startup on startup and scheduler_shutdown on shutdown
  </verify>
  <done>
- APScheduler starts on API startup
- Schedules loaded from database on startup
- Scheduler shuts down gracefully on API shutdown
  </done>
</task>

</tasks>

<verification>
1. APScheduler starts on API startup (check logs for "APScheduler started")
2. GET /collection/schedule returns schedule config with defaults
3. PATCH /collection/schedule validates cron and updates database
4. Scheduler loads enabled schedules from database on startup
5. Invalid cron expressions return 400 error
</verification>

<success_criteria>
- APScheduler integrated and starts with API
- Schedule CRUD endpoints work with cron validation
- Schedules persist in database and reload on restart
- Scheduled runs check for active collections before starting
</success_criteria>

<output>
After completion, create `.planning/phases/09-storage-export-collection-ui/09-04-SUMMARY.md`
</output>
