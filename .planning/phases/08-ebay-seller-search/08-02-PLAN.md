---
phase: 08-ebay-seller-search
plan: 02
type: execute
wave: 2
depends_on: ["08-01"]
files_modified:
  - apps/api/src/app/services/collection.py
  - apps/api/src/app/routers/collection.py
autonomous: true

must_haves:
  truths:
    - "Each Amazon product triggers eBay search with product title"
    - "Sellers extracted and deduplicated against existing database"
    - "Collection execution chains Amazon fetch then eBay search"
    - "Progress updates checkpoint with eBay search status"
  artifacts:
    - path: "apps/api/src/app/services/collection.py"
      provides: "run_ebay_seller_search method"
      contains: "async def run_ebay_seller_search"
    - path: "apps/api/src/app/routers/collection.py"
      provides: "execute-ebay endpoint"
      contains: "execute-ebay"
  key_links:
    - from: "apps/api/src/app/services/collection.py"
      to: "apps/api/src/app/services/scrapers/oxylabs_ebay.py"
      via: "OxylabsEbayScraper import"
      pattern: "from app.services.scrapers import.*OxylabsEbayScraper"
    - from: "collection.py run_ebay_seller_search"
      to: "collection_items table"
      via: "SELECT amazon_product items"
      pattern: 'item_type.*amazon_product'
    - from: "collection.py run_ebay_seller_search"
      to: "sellers table"
      via: "INSERT new sellers"
      pattern: 'sellers.*insert'
---

<objective>
Integrate eBay scraper into collection pipeline to search for dropshippers based on Amazon products.

Purpose: For each Amazon product collected in Phase 7, search eBay with the product title and dropshipper filters, extract sellers, dedupe against existing database, and store new sellers.

Output: CollectionService method for eBay seller search and API endpoint to trigger it.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/08-ebay-seller-search/08-CONTEXT.md
@.planning/phases/08-ebay-seller-search/08-RESEARCH.md
@.planning/phases/08-ebay-seller-search/08-01-SUMMARY.md
@apps/api/src/app/services/collection.py
@apps/api/src/app/routers/collection.py
@apps/api/migrations/037_collection_infrastructure.sql
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add run_ebay_seller_search method to CollectionService</name>
  <files>apps/api/src/app/services/collection.py</files>
  <action>
Add import at top of file:
```python
from app.services.scrapers import OxylabsEbayScraper
```

Add new method `run_ebay_seller_search` to CollectionService class. Place it after `run_amazon_collection` method.

Method signature:
```python
async def run_ebay_seller_search(
    self,
    run_id: str,
    org_id: str,
) -> dict:
```

Implementation:
1. Get Amazon products from collection_items table:
   - SELECT id, external_id, data FROM collection_items
   - WHERE run_id = run_id AND item_type = 'amazon_product'
   - If no products, return {"status": "completed", "message": "No Amazon products to search", "sellers_found": 0, "sellers_new": 0}

2. Initialize OxylabsEbayScraper (wrap in try/except for missing credentials)

3. Set constants:
   - MAX_CONSECUTIVE_FAILURES = 5
   - PAGES_PER_PRODUCT = 3 (per CONTEXT.md: 2-3 pages)
   - REQUEST_DELAY_MS = 200 (Claude's discretion, within 0-500ms range from CONTEXT.md)

4. Track progress:
   - consecutive_failures = 0
   - sellers_found = 0
   - sellers_new = 0
   - products_processed = 0

5. For each product in products:
   - Extract title and price from product["data"]
   - Skip if title or price is missing (log warning)
   - For page in range(1, PAGES_PER_PRODUCT + 1):
     - Call scraper.search_sellers(title, price, page)
     - Handle rate_limited error: update checkpoint with throttle status, sleep 5s, continue
     - Handle other errors: increment consecutive_failures, check for pause threshold
     - On success: reset consecutive_failures
     - Process sellers - dedupe immediately against existing:
       - For each seller in result.sellers:
         - Normalize username with _normalize_seller_name
         - Check if exists: SELECT id FROM sellers WHERE org_id = org_id AND normalized_name = normalized AND platform = 'ebay'
         - If not exists, INSERT new seller with:
           - org_id, display_name=username, normalized_name, platform='ebay'
           - platform_id=username
           - feedback_score=seller.feedback_count
           - first_seen_run_id=run_id, last_seen_run_id=run_id, times_seen=1
         - Increment sellers_found and sellers_new counters
     - If not result.has_more, break (stop pagination early)
     - Add small delay between pages: await asyncio.sleep(REQUEST_DELAY_MS / 1000)

6. Update checkpoint after each product:
   - checkpoint_data with current_product_id, products_processed, products_total
   - Update products_searched in enhanced progress

7. If 5 consecutive failures, pause run:
   - Call pause_run(run_id, org_id)
   - Update checkpoint with status="paused_failures"
   - Return {"status": "paused", "error": "Multiple consecutive failures", ...}

8. After all products processed:
   - Update run status to "completed" if it was Amazon+eBay combined run
   - Return {"status": "completed", "sellers_found": N, "sellers_new": N}

Log progress with logger.info at key points.
  </action>
  <verify>
```bash
cd /mnt/c/Users/User/Downloads/GitRepos/DS-ProSolution/apps/api && python -c "
from app.services.collection import CollectionService
import inspect
assert hasattr(CollectionService, 'run_ebay_seller_search'), 'Method missing'
sig = inspect.signature(CollectionService.run_ebay_seller_search)
params = list(sig.parameters.keys())
assert 'run_id' in params and 'org_id' in params, 'Missing required params'
print('run_ebay_seller_search method exists with correct signature')
"
```
  </verify>
  <done>CollectionService has run_ebay_seller_search method that processes Amazon products and extracts eBay sellers</done>
</task>

<task type="auto">
  <name>Task 2: Add eBay execution endpoint and chain execution</name>
  <files>apps/api/src/app/routers/collection.py</files>
  <action>
Add new endpoint `/runs/{run_id}/execute-ebay` for standalone eBay search execution:

```python
@router.post("/runs/{run_id}/execute-ebay")
async def execute_ebay_search(
    run_id: str,
    background_tasks: BackgroundTasks,
    user: dict = Depends(require_permission_key("admin.automation")),
    service: CollectionService = Depends(get_collection_service),
):
    """
    Execute eBay seller search for Amazon products in a collection run.

    Searches eBay for each Amazon product with dropshipper filters,
    extracts sellers, and stores new ones (deduped).

    The run must be in 'running' status.

    Requires admin.automation permission.
    """
    org_id = user["membership"]["org_id"]
    run = await service.get_run(run_id, org_id)

    if not run:
        raise HTTPException(status_code=404, detail="Run not found")

    if run["status"] != "running":
        raise HTTPException(
            status_code=400,
            detail=f"Run must be in 'running' status (current: {run['status']})"
        )

    # Start eBay search in background
    async def run_ebay_search():
        await service.run_ebay_seller_search(run_id=run_id, org_id=org_id)

    background_tasks.add_task(run_ebay_search)

    return {"ok": True, "message": "eBay seller search started", "run_id": run_id}
```

Modify existing `/runs/{run_id}/execute` endpoint to chain Amazon -> eBay:

Update the `run_collection` inner function to:
1. First run Amazon collection (existing)
2. If Amazon completed successfully, automatically start eBay search
3. Update final status after both phases complete

```python
async def run_collection():
    # Phase 1: Amazon collection
    amazon_result = await service.run_amazon_collection(
        run_id=run_id,
        org_id=org_id,
        category_ids=run["category_ids"],
    )

    # If Amazon failed or was paused, don't continue to eBay
    if amazon_result.get("status") in ("failed", "paused"):
        return

    # Phase 2: eBay seller search
    await service.run_ebay_seller_search(run_id=run_id, org_id=org_id)
```

Update the success message to reflect the full pipeline: "Collection started (Amazon + eBay)"
  </action>
  <verify>
```bash
cd /mnt/c/Users/User/Downloads/GitRepos/DS-ProSolution/apps/api && python -c "
from app.routers.collection import router
routes = [r.path for r in router.routes]
assert '/runs/{run_id}/execute-ebay' in routes, 'execute-ebay endpoint missing'
assert '/runs/{run_id}/execute' in routes, 'execute endpoint missing'
print('Both execute endpoints present')
"
```
  </verify>
  <done>execute-ebay endpoint added and execute endpoint chains Amazon -> eBay collection</done>
</task>

</tasks>

<verification>
Verify collection service has eBay method:
```bash
cd /mnt/c/Users/User/Downloads/GitRepos/DS-ProSolution/apps/api && python -c "
from app.services.collection import CollectionService
from app.services.scrapers import OxylabsEbayScraper
print('CollectionService and OxylabsEbayScraper imports work')
assert hasattr(CollectionService, 'run_ebay_seller_search')
print('run_ebay_seller_search method exists')
"
```

Verify router endpoints:
```bash
cd /mnt/c/Users/User/Downloads/GitRepos/DS-ProSolution/apps/api && python -c "
from app.routers.collection import router
endpoints = {r.path: r.methods for r in router.routes if hasattr(r, 'methods')}
print('Collection endpoints:')
for path, methods in sorted(endpoints.items()):
    print(f'  {methods} {path}')
assert '/runs/{run_id}/execute-ebay' in endpoints
print('execute-ebay endpoint verified')
"
```
</verification>

<success_criteria>
- CollectionService.run_ebay_seller_search fetches Amazon products from collection_items
- For each product, searches eBay with title and dropshipper filters
- Sellers deduped against existing database before insert
- Rate limiting handled with checkpoint update and sleep
- 5 consecutive failures triggers auto-pause
- /runs/{run_id}/execute-ebay endpoint triggers eBay search only
- /runs/{run_id}/execute chains Amazon -> eBay automatically
- Progress tracked via checkpoint updates
</success_criteria>

<output>
After completion, create `.planning/phases/08-ebay-seller-search/08-02-SUMMARY.md`
</output>
