---
phase: 18-client-persistence
plan: 02
type: execute
wave: 2
depends_on: ["18-01"]
files_modified:
  - apps/web/src/lib/db/sync.ts
  - apps/web/src/hooks/sync/use-sync-records.ts
  - apps/web/src/hooks/sync/use-prefetch-on-scroll.ts
  - apps/web/src/hooks/queries/use-records-infinite.ts
  - apps/web/src/hooks/queries/use-accounts.ts
autonomous: true

must_haves:
  truths:
    - "Records load instantly from IndexedDB on subsequent visits"
    - "Background sync fetches only changed records (incremental)"
    - "Next page prefetches before user scrolls to bottom"
    - "Deleted records on server are removed from local cache"
  artifacts:
    - path: "apps/web/src/lib/db/sync.ts"
      provides: "Sync engine with per-table checkpoints"
      exports: ["syncRecords", "syncAccounts", "syncSellers"]
    - path: "apps/web/src/hooks/sync/use-sync-records.ts"
      provides: "Cache-first hook for records with useLiveQuery"
      exports: ["useSyncRecords"]
    - path: "apps/web/src/hooks/sync/use-prefetch-on-scroll.ts"
      provides: "Prefetch trigger at scroll threshold"
      exports: ["usePrefetchOnScroll"]
    - path: "apps/web/src/hooks/queries/use-records-infinite.ts"
      provides: "Updated hook using sync endpoint"
      exports: ["useRecordsInfinite"]
  key_links:
    - from: "apps/web/src/hooks/sync/use-sync-records.ts"
      to: "apps/web/src/lib/db/sync.ts"
      via: "import syncRecords"
      pattern: "from.*db/sync"
    - from: "apps/web/src/hooks/sync/use-sync-records.ts"
      to: "apps/web/src/lib/db/index.ts"
      via: "useLiveQuery on db.records"
      pattern: "useLiveQuery.*db\\.records"
    - from: "apps/web/src/lib/db/sync.ts"
      to: "apps/web/src/lib/api.ts"
      via: "api.syncRecords call"
      pattern: "api\\.syncRecords"
---

<objective>
Implement sync engine and cache-first hooks for instant data loading.

Purpose: Enable instant page loads from IndexedDB cache while syncing changes from server in background. Users see data immediately instead of waiting for network.

Output: Sync engine that tracks incremental updates, cache-first hooks using useLiveQuery, and prefetch hook for predictive loading.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/18-client-persistence/18-CONTEXT.md
@.planning/phases/18-client-persistence/18-RESEARCH.md
@.planning/phases/18-client-persistence/18-01-SUMMARY.md

# Files from Plan 01
@apps/web/src/lib/db/index.ts
@apps/web/src/lib/db/schema.ts
@apps/web/src/lib/api.ts

# Existing hooks to update
@apps/web/src/hooks/queries/use-records-infinite.ts
@apps/web/src/hooks/queries/use-accounts.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create sync engine with per-table checkpoints</name>
  <files>apps/web/src/lib/db/sync.ts</files>
  <action>
Create the sync engine that fetches changed records since last sync and updates IndexedDB.

**apps/web/src/lib/db/sync.ts**:
```typescript
import { db, type BookkeepingRecord } from './index';
import { api, type RecordSyncItem, type AccountSyncItem, type SellerSyncItem } from '@/lib/api';

export interface SyncResult {
  synced: number;
  deleted: number;
  hasMore: boolean;
}

/**
 * Sync records for a specific account from server to IndexedDB.
 * Uses incremental sync - only fetches records updated since last sync.
 * Handles soft deletes by removing deleted records from local cache.
 */
export async function syncRecords(accountId: string): Promise<SyncResult> {
  const metaKey = `records:${accountId}`;
  const meta = await db._sync_meta.get(metaKey);

  let cursor: string | null = meta?.cursor ?? null;
  let totalSynced = 0;
  let totalDeleted = 0;
  let hasMore = true;

  try {
    while (hasMore) {
      const response = await api.syncRecords({
        account_id: accountId,
        cursor,
        limit: 100,
        include_deleted: true, // Need to detect server-side deletions
        updated_since: meta?.last_sync_at,
      });

      // Separate active vs deleted records
      const active: BookkeepingRecord[] = [];
      const toDelete: string[] = [];

      for (const item of response.items) {
        if (item.deleted_at) {
          toDelete.push(item.id);
        } else {
          // Map sync item to local record (status as string)
          active.push({
            ...item,
            status: item.status as string,
          });
        }
      }

      // Bulk upsert active records
      if (active.length > 0) {
        await db.records.bulkPut(active);
        totalSynced += active.length;
      }

      // Delete soft-deleted records locally
      if (toDelete.length > 0) {
        await db.records.bulkDelete(toDelete);
        totalDeleted += toDelete.length;
      }

      cursor = response.next_cursor;
      hasMore = response.has_more;

      // Save cursor for resume if interrupted
      if (hasMore && cursor) {
        await db._sync_meta.put({
          table_name: metaKey,
          last_sync_at: meta?.last_sync_at ?? new Date().toISOString(),
          cursor,
        });
      }
    }

    // Update sync checkpoint after complete sync
    await db._sync_meta.put({
      table_name: metaKey,
      last_sync_at: new Date().toISOString(),
      cursor: null, // Reset cursor for next incremental sync
    });

    console.log(`[Sync] Records for ${accountId}: synced=${totalSynced}, deleted=${totalDeleted}`);
    return { synced: totalSynced, deleted: totalDeleted, hasMore: false };
  } catch (error) {
    console.error(`[Sync] Failed to sync records for ${accountId}:`, error);
    throw error;
  }
}

/**
 * Sync accounts from server to IndexedDB.
 */
export async function syncAccounts(): Promise<SyncResult> {
  const metaKey = 'accounts';
  const meta = await db._sync_meta.get(metaKey);

  let cursor: string | null = meta?.cursor ?? null;
  let totalSynced = 0;
  let totalDeleted = 0;
  let hasMore = true;

  try {
    while (hasMore) {
      const response = await api.syncAccounts({
        cursor,
        limit: 100,
        include_deleted: true,
        updated_since: meta?.last_sync_at,
      });

      const active: AccountSyncItem[] = [];
      const toDelete: string[] = [];

      for (const item of response.items) {
        if (item.deleted_at) {
          toDelete.push(item.id);
        } else {
          active.push(item);
        }
      }

      if (active.length > 0) {
        await db.accounts.bulkPut(active);
        totalSynced += active.length;
      }

      if (toDelete.length > 0) {
        await db.accounts.bulkDelete(toDelete);
        totalDeleted += toDelete.length;
      }

      cursor = response.next_cursor;
      hasMore = response.has_more;
    }

    await db._sync_meta.put({
      table_name: metaKey,
      last_sync_at: new Date().toISOString(),
      cursor: null,
    });

    console.log(`[Sync] Accounts: synced=${totalSynced}, deleted=${totalDeleted}`);
    return { synced: totalSynced, deleted: totalDeleted, hasMore: false };
  } catch (error) {
    console.error('[Sync] Failed to sync accounts:', error);
    throw error;
  }
}

/**
 * Sync sellers from server to IndexedDB.
 */
export async function syncSellers(): Promise<SyncResult> {
  const metaKey = 'sellers';
  const meta = await db._sync_meta.get(metaKey);

  let cursor: string | null = meta?.cursor ?? null;
  let totalSynced = 0;
  let totalDeleted = 0;
  let hasMore = true;

  try {
    while (hasMore) {
      const response = await api.syncSellers({
        cursor,
        limit: 100,
        include_deleted: true,
        updated_since: meta?.last_sync_at,
      });

      const active: SellerSyncItem[] = [];
      const toDelete: string[] = [];

      for (const item of response.items) {
        if (item.deleted_at) {
          toDelete.push(item.id);
        } else {
          active.push(item);
        }
      }

      if (active.length > 0) {
        await db.sellers.bulkPut(active);
        totalSynced += active.length;
      }

      if (toDelete.length > 0) {
        await db.sellers.bulkDelete(toDelete);
        totalDeleted += toDelete.length;
      }

      cursor = response.next_cursor;
      hasMore = response.has_more;
    }

    await db._sync_meta.put({
      table_name: metaKey,
      last_sync_at: new Date().toISOString(),
      cursor: null,
    });

    console.log(`[Sync] Sellers: synced=${totalSynced}, deleted=${totalDeleted}`);
    return { synced: totalSynced, deleted: totalDeleted, hasMore: false };
  } catch (error) {
    console.error('[Sync] Failed to sync sellers:', error);
    throw error;
  }
}

/**
 * Get last sync time for a table.
 * Used for displaying "Last synced X ago" UI (Phase 19).
 */
export async function getLastSyncTime(tableKey: string): Promise<string | null> {
  const meta = await db._sync_meta.get(tableKey);
  return meta?.last_sync_at ?? null;
}

/**
 * Clear all local data and sync metadata.
 * Used for error recovery or user-initiated refresh.
 */
export async function clearAllData(): Promise<void> {
  await db.transaction('rw', [db.accounts, db.records, db.sellers, db._sync_meta], async () => {
    await db.accounts.clear();
    await db.records.clear();
    await db.sellers.clear();
    await db._sync_meta.clear();
  });
  console.log('[Sync] Cleared all local data');
}
```

Key decisions:
- Incremental sync using updated_since parameter
- Saves cursor during sync for resume on interruption
- Handles soft deletes by removing from local cache
- Exports getLastSyncTime for Phase 19 sync status UI
- Exports clearAllData for error recovery
  </action>
  <verify>
TypeScript compilation passes: `cd apps/web && npx tsc --noEmit`
  </verify>
  <done>
- Sync engine file exists with syncRecords, syncAccounts, syncSellers exports
- Uses incremental sync (updated_since from _sync_meta)
- Handles soft deletes correctly (removes from local cache)
- Updates checkpoint after complete sync
  </done>
</task>

<task type="auto">
  <name>Task 2: Create cache-first hooks with useLiveQuery</name>
  <files>
    apps/web/src/hooks/sync/use-sync-records.ts
    apps/web/src/hooks/sync/use-prefetch-on-scroll.ts
  </files>
  <action>
Create hooks that read from IndexedDB first and sync in background.

**apps/web/src/hooks/sync/use-sync-records.ts**:
```typescript
'use client';

import { useLiveQuery } from 'dexie-react-hooks';
import { useEffect, useRef, useCallback } from 'react';
import { db, type BookkeepingRecord } from '@/lib/db';
import { syncRecords } from '@/lib/db/sync';
import type { BookkeepingStatus } from '@/lib/api';

interface UseSyncRecordsOptions {
  accountId: string;
  filters?: {
    status?: BookkeepingStatus;
    dateFrom?: string;
    dateTo?: string;
  };
}

interface UseSyncRecordsResult {
  records: BookkeepingRecord[];
  isLoading: boolean;
  isSyncing: boolean;
  error: Error | null;
  refetch: () => void;
}

/**
 * Cache-first hook for records.
 * Returns data from IndexedDB immediately, syncs from server in background.
 * Uses useLiveQuery for reactive updates when IndexedDB changes.
 */
export function useSyncRecords({ accountId, filters }: UseSyncRecordsOptions): UseSyncRecordsResult {
  const syncingRef = useRef(false);
  const errorRef = useRef<Error | null>(null);

  // Live query - reactive to IndexedDB changes
  const records = useLiveQuery(async () => {
    const results = await db.records
      .where('account_id')
      .equals(accountId)
      .toArray();

    // Apply additional filters in memory (Dexie compound indexes have limitations)
    return results
      .filter((r) => {
        if (filters?.status && r.status !== filters.status) return false;
        if (filters?.dateFrom && r.sale_date < filters.dateFrom) return false;
        if (filters?.dateTo && r.sale_date > filters.dateTo) return false;
        return true;
      })
      .sort((a, b) => {
        // Sort by sale_date DESC, then id DESC (match server order)
        const dateCompare = b.sale_date.localeCompare(a.sale_date);
        if (dateCompare !== 0) return dateCompare;
        return b.id.localeCompare(a.id);
      });
  }, [accountId, filters?.status, filters?.dateFrom, filters?.dateTo]);

  // Sync function that can be called manually or on mount
  const doSync = useCallback(async () => {
    if (syncingRef.current) return;
    syncingRef.current = true;
    errorRef.current = null;

    try {
      await syncRecords(accountId);
    } catch (err) {
      errorRef.current = err instanceof Error ? err : new Error('Sync failed');
      console.error('[useSyncRecords] Sync failed:', err);
    } finally {
      syncingRef.current = false;
    }
  }, [accountId]);

  // Background sync on mount
  useEffect(() => {
    doSync();
  }, [doSync]);

  return {
    records: records ?? [],
    isLoading: records === undefined,
    isSyncing: syncingRef.current,
    error: errorRef.current,
    refetch: doSync,
  };
}
```

**apps/web/src/hooks/sync/use-prefetch-on-scroll.ts**:
```typescript
'use client';

import { useEffect } from 'react';
import { useInView } from 'react-intersection-observer';

interface UsePrefetchOnScrollOptions {
  hasNextPage: boolean;
  isFetching: boolean;
  fetchNextPage: () => void;
  threshold?: number; // 0-1, default 0.75 (75%)
}

interface UsePrefetchOnScrollResult {
  prefetchSentinelRef: (node?: Element | null) => void;
}

/**
 * Triggers prefetch when user scrolls to threshold position.
 * Uses IntersectionObserver for efficient scroll detection.
 *
 * Place the sentinel element at the end of your list:
 * <div ref={prefetchSentinelRef} style={{ height: 1 }} />
 */
export function usePrefetchOnScroll({
  hasNextPage,
  isFetching,
  fetchNextPage,
  threshold = 0.75,
}: UsePrefetchOnScrollOptions): UsePrefetchOnScrollResult {
  const { ref, inView } = useInView({
    threshold: 0,
    // Trigger when sentinel is (1-threshold) of viewport height away
    // e.g., threshold 0.75 means trigger when 25% from bottom
    rootMargin: `${Math.round((1 - threshold) * 100)}% 0px`,
  });

  useEffect(() => {
    if (inView && hasNextPage && !isFetching) {
      console.log('[Prefetch] Triggering next page fetch');
      fetchNextPage();
    }
  }, [inView, hasNextPage, isFetching, fetchNextPage]);

  return { prefetchSentinelRef: ref };
}
```

Create the hooks/sync directory if it doesn't exist.
  </action>
  <verify>
TypeScript compilation passes: `cd apps/web && npx tsc --noEmit`
  </verify>
  <done>
- useSyncRecords hook exists with cache-first behavior
- useLiveQuery provides reactive updates from IndexedDB
- Background sync runs on mount
- usePrefetchOnScroll hook exists with configurable threshold
  </done>
</task>

<task type="auto">
  <name>Task 3: Update existing hooks to use sync endpoint and cache</name>
  <files>
    apps/web/src/hooks/queries/use-records-infinite.ts
    apps/web/src/hooks/queries/use-accounts.ts
  </files>
  <action>
Update the existing TanStack Query hooks to use the sync endpoints and integrate with cache.

**apps/web/src/hooks/queries/use-records-infinite.ts** - Update to use sync endpoint:
```typescript
import { useInfiniteQuery } from "@tanstack/react-query";
import { queryKeys, type RecordFilters } from "@/lib/query-keys";
import { api, type BookkeepingRecord, type RecordSyncItem, type BookkeepingStatus } from "@/lib/api";

/**
 * Response shape for infinite query pages.
 */
interface RecordsPage {
  items: BookkeepingRecord[];
  nextCursor: string | null;
  hasMore: boolean;
}

/**
 * Compute derived fields for a record (profit, earnings, COGS).
 * Server sends raw data for sync; computed fields are calculated client-side.
 */
function computeRecordFields(item: RecordSyncItem): BookkeepingRecord {
  const salePriceCents = item.sale_price_cents ?? 0;
  const ebayFeesCents = item.ebay_fees_cents ?? 0;
  const amazonPriceCents = item.amazon_price_cents ?? 0;
  const amazonTaxCents = item.amazon_tax_cents ?? 0;
  const amazonShippingCents = item.amazon_shipping_cents ?? 0;
  const returnLabelCostCents = item.return_label_cost_cents ?? 0;

  const earningsNetCents = salePriceCents - ebayFeesCents;
  const cogsTotalCents = amazonPriceCents + amazonTaxCents + amazonShippingCents;
  const profitCents = earningsNetCents - cogsTotalCents - returnLabelCostCents;

  return {
    id: item.id,
    account_id: item.account_id,
    ebay_order_id: item.ebay_order_id,
    sale_date: item.sale_date,
    item_name: item.item_name,
    qty: item.qty,
    sale_price_cents: item.sale_price_cents,
    ebay_fees_cents: item.ebay_fees_cents,
    amazon_price_cents: item.amazon_price_cents,
    amazon_tax_cents: item.amazon_tax_cents,
    amazon_shipping_cents: item.amazon_shipping_cents,
    amazon_order_id: item.amazon_order_id,
    status: item.status,
    return_label_cost_cents: item.return_label_cost_cents,
    order_remark: item.order_remark,
    service_remark: item.service_remark,
    // Computed fields
    earnings_net_cents: earningsNetCents,
    cogs_total_cents: cogsTotalCents,
    profit_cents: profitCents,
  };
}

/**
 * Infinite query hook for fetching records with cursor pagination.
 * Uses the sync endpoint for efficient incremental fetching.
 *
 * @param orgId - Organization ID to scope the query
 * @param accountId - Account ID to filter records
 * @param filters - Optional filters (date range, status)
 */
export function useRecordsInfinite(
  orgId: string,
  accountId: string,
  filters?: RecordFilters
) {
  return useInfiniteQuery<RecordsPage, Error>({
    queryKey: queryKeys.records.infinite(orgId, accountId, filters),
    queryFn: async ({ pageParam }) => {
      const response = await api.syncRecords({
        account_id: accountId,
        cursor: pageParam as string | null,
        limit: 50,
        include_deleted: false,
        status: filters?.status,
        // Note: date filters would need server-side support
        // For now, filtering done in useSyncRecords hook
      });

      return {
        items: response.items.map(computeRecordFields),
        nextCursor: response.next_cursor,
        hasMore: response.has_more,
      };
    },
    initialPageParam: null as string | null,
    getNextPageParam: (lastPage) =>
      lastPage.hasMore ? lastPage.nextCursor : undefined,
    // Records change frequently - 30 second stale time
    staleTime: 30 * 1000,
  });
}
```

**apps/web/src/hooks/queries/use-accounts.ts** - Keep as is for now:
The accounts hook doesn't need changes yet - it's used for the account selector which benefits from simple server fetch. Cache-first for accounts will be added when needed.

Add a comment indicating Phase 18 decision:
```typescript
import { useQuery } from "@tanstack/react-query";
import { queryKeys } from "@/lib/query-keys";
import { api, type Account } from "@/lib/api";

/**
 * Query hook for fetching accounts.
 * Accounts rarely change, so we use a longer stale time (5 minutes).
 *
 * Note: This hook fetches directly from server. For cache-first behavior,
 * use useSyncAccounts from hooks/sync/ which reads from IndexedDB.
 * The server-fetch approach is kept for account selector dropdowns
 * where fresh data is preferred over cached data.
 *
 * @param orgId - Organization ID to scope the query
 */
export function useAccounts(orgId: string) {
  return useQuery<Account[], Error>({
    queryKey: queryKeys.accounts.list(orgId),
    queryFn: () => api.getAccounts(),
    // Accounts rarely change - 5 minute stale time
    staleTime: 5 * 60 * 1000,
  });
}
```
  </action>
  <verify>
1. TypeScript compilation passes: `cd apps/web && npx tsc --noEmit`
2. Existing bookkeeping view still loads records correctly
  </verify>
  <done>
- useRecordsInfinite uses sync endpoint with cursor pagination
- Computed fields (profit, earnings, COGS) calculated client-side
- useAccounts has clarifying comment about cache strategy
  </done>
</task>

</tasks>

<verification>
After all tasks complete:

1. **Build check:** `cd apps/web && npm run build` passes
2. **Type check:** `cd apps/web && npx tsc --noEmit` passes
3. **Functional test:**
   - Start dev server
   - Load bookkeeping page
   - Check browser devtools IndexedDB - records should be populated
   - Refresh page - records should load instantly from cache
   - Check console for sync logs showing incremental sync behavior
</verification>

<success_criteria>
- Sync engine fetches data incrementally (only changes since last sync)
- useSyncRecords returns data from IndexedDB via useLiveQuery
- Background sync updates IndexedDB after returning cached data
- Soft deletes on server result in local record deletion
- usePrefetchOnScroll triggers fetch at configurable scroll threshold
- useRecordsInfinite uses sync endpoint with proper cursor handling
- Computed fields calculated client-side from raw sync data
</success_criteria>

<output>
After completion, create `.planning/phases/18-client-persistence/18-02-SUMMARY.md`
</output>
