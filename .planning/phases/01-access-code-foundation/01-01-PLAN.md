---
phase: 01-access-code-foundation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - apps/api/pyproject.toml
  - apps/api/migrations/035_access_codes.sql
  - apps/api/src/app/models.py
autonomous: true

must_haves:
  truths:
    - "Access code table exists with prefix, hashed_secret, user_id columns"
    - "Rate limit tracking tables exist for IP and prefix-based limiting"
    - "Pydantic models validate access code request/response shapes"
  artifacts:
    - path: "apps/api/migrations/035_access_codes.sql"
      provides: "Database schema for access codes and rate limiting"
      contains: "CREATE TABLE access_codes"
    - path: "apps/api/pyproject.toml"
      provides: "New dependencies installed"
      contains: "argon2-cffi"
    - path: "apps/api/src/app/models.py"
      provides: "AccessCode Pydantic models"
      contains: "AccessCodeGenerateResponse"
  key_links:
    - from: "apps/api/migrations/035_access_codes.sql"
      to: "access_codes table"
      via: "CREATE TABLE"
      pattern: "CREATE TABLE access_codes"
---

<objective>
Set up database schema and dependencies for access code system.

Purpose: Establish the foundation that service layer and API endpoints will build upon. Without the schema, nothing can be stored. Without the models, nothing can be validated.

Output:
- SQL migration creating access_codes table and rate limiting tables
- Updated pyproject.toml with argon2-cffi and slowapi dependencies
- Pydantic models for access code requests and responses
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/01-access-code-foundation/01-CONTEXT.md
@.planning/phases/01-access-code-foundation/01-RESEARCH.md

Existing codebase patterns:
@apps/api/pyproject.toml
@apps/api/src/app/models.py
@apps/api/migrations/028_automation.sql (for migration pattern reference)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add dependencies to pyproject.toml</name>
  <files>apps/api/pyproject.toml</files>
  <action>
Add two new dependencies to the `dependencies` list:
- "argon2-cffi>=25.1.0" - for Argon2id password hashing
- "slowapi>=0.1.9" - for rate limiting

These go in the main dependencies section (not dev). Keep existing dependencies, just append these two.

After editing, run `pip install -e ".[dev]"` from apps/api directory to install.
  </action>
  <verify>Run `pip show argon2-cffi` and `pip show slowapi` to confirm both are installed</verify>
  <done>Both argon2-cffi and slowapi appear in pip show output with correct versions</done>
</task>

<task type="auto">
  <name>Task 2: Create database migration for access codes</name>
  <files>apps/api/migrations/035_access_codes.sql</files>
  <action>
Create migration file `apps/api/migrations/035_access_codes.sql` with:

**1. access_codes table:**
```sql
CREATE TABLE access_codes (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  user_id UUID NOT NULL REFERENCES auth.users(id) ON DELETE CASCADE,
  org_id UUID NOT NULL REFERENCES orgs(id) ON DELETE CASCADE,
  prefix VARCHAR(4) NOT NULL,
  hashed_secret TEXT NOT NULL,
  created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
  expires_at TIMESTAMPTZ NOT NULL,
  rotated_at TIMESTAMPTZ,

  CONSTRAINT access_codes_prefix_unique UNIQUE (prefix),
  CONSTRAINT access_codes_user_org_unique UNIQUE (user_id, org_id)
);
```

Key design decisions:
- `prefix` is VARCHAR(4), globally unique for O(1) lookup
- `hashed_secret` is TEXT (Argon2 hashes are ~100 chars)
- `user_org_unique` ensures one code per user per org
- `expires_at` for 90-day expiration
- `rotated_at` tracks when secret was last changed

**2. access_code_attempts table (for rate limiting):**
```sql
CREATE TABLE access_code_attempts (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  prefix VARCHAR(4),
  ip_address INET NOT NULL,
  attempted_at TIMESTAMPTZ NOT NULL DEFAULT now(),
  success BOOLEAN NOT NULL DEFAULT false
);

CREATE INDEX idx_access_code_attempts_prefix_time
  ON access_code_attempts(prefix, attempted_at DESC);
CREATE INDEX idx_access_code_attempts_ip_time
  ON access_code_attempts(ip_address, attempted_at DESC);
```

**3. access_code_lockouts table (for progressive lockouts):**
```sql
CREATE TABLE access_code_lockouts (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  prefix VARCHAR(4),
  ip_address INET,
  lockout_level INT NOT NULL DEFAULT 1,
  lockout_until TIMESTAMPTZ NOT NULL,
  created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
  updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),

  CONSTRAINT access_code_lockouts_prefix_unique UNIQUE (prefix),
  CONSTRAINT access_code_lockouts_ip_unique UNIQUE (ip_address)
);
```

**4. RPC function for atomic rate limit check:**
```sql
CREATE OR REPLACE FUNCTION check_access_code_rate_limit(
  p_prefix TEXT,
  p_ip INET,
  p_window_seconds INT DEFAULT 300,
  p_max_attempts INT DEFAULT 10
) RETURNS TABLE (
  allowed BOOLEAN,
  retry_after_seconds INT,
  lockout_level INT
) AS $$
DECLARE
  v_prefix_lockout RECORD;
  v_ip_lockout RECORD;
  v_prefix_attempts INT;
  v_ip_attempts INT;
  v_lockout_duration INT;
  v_new_lockout_level INT;
BEGIN
  -- Check existing prefix lockout
  SELECT * INTO v_prefix_lockout
  FROM access_code_lockouts
  WHERE prefix = p_prefix AND lockout_until > NOW();

  IF v_prefix_lockout IS NOT NULL THEN
    RETURN QUERY SELECT
      FALSE,
      EXTRACT(EPOCH FROM (v_prefix_lockout.lockout_until - NOW()))::INT,
      v_prefix_lockout.lockout_level;
    RETURN;
  END IF;

  -- Check existing IP lockout
  SELECT * INTO v_ip_lockout
  FROM access_code_lockouts
  WHERE ip_address = p_ip AND lockout_until > NOW();

  IF v_ip_lockout IS NOT NULL THEN
    RETURN QUERY SELECT
      FALSE,
      EXTRACT(EPOCH FROM (v_ip_lockout.lockout_until - NOW()))::INT,
      v_ip_lockout.lockout_level;
    RETURN;
  END IF;

  -- Count recent failed attempts by prefix
  SELECT COUNT(*) INTO v_prefix_attempts
  FROM access_code_attempts
  WHERE prefix = p_prefix
    AND attempted_at > NOW() - (p_window_seconds || ' seconds')::INTERVAL
    AND success = FALSE;

  -- Count recent failed attempts by IP
  SELECT COUNT(*) INTO v_ip_attempts
  FROM access_code_attempts
  WHERE ip_address = p_ip
    AND attempted_at > NOW() - (p_window_seconds || ' seconds')::INTERVAL
    AND success = FALSE;

  -- Check if either limit exceeded
  IF v_prefix_attempts >= p_max_attempts THEN
    -- Get or create lockout level for prefix
    SELECT lockout_level INTO v_new_lockout_level
    FROM access_code_lockouts WHERE prefix = p_prefix;

    v_new_lockout_level := COALESCE(v_new_lockout_level, 0) + 1;

    -- Progressive lockout: 5min, 15min, 1hr
    v_lockout_duration := CASE
      WHEN v_new_lockout_level = 1 THEN 300
      WHEN v_new_lockout_level = 2 THEN 900
      ELSE 3600
    END;

    INSERT INTO access_code_lockouts (prefix, lockout_level, lockout_until, updated_at)
    VALUES (p_prefix, v_new_lockout_level, NOW() + (v_lockout_duration || ' seconds')::INTERVAL, NOW())
    ON CONFLICT (prefix) DO UPDATE SET
      lockout_level = v_new_lockout_level,
      lockout_until = NOW() + (v_lockout_duration || ' seconds')::INTERVAL,
      updated_at = NOW();

    RETURN QUERY SELECT FALSE, v_lockout_duration, v_new_lockout_level;
    RETURN;
  END IF;

  IF v_ip_attempts >= p_max_attempts THEN
    -- Similar logic for IP
    SELECT lockout_level INTO v_new_lockout_level
    FROM access_code_lockouts WHERE ip_address = p_ip;

    v_new_lockout_level := COALESCE(v_new_lockout_level, 0) + 1;

    v_lockout_duration := CASE
      WHEN v_new_lockout_level = 1 THEN 300
      WHEN v_new_lockout_level = 2 THEN 900
      ELSE 3600
    END;

    INSERT INTO access_code_lockouts (ip_address, lockout_level, lockout_until, updated_at)
    VALUES (p_ip, v_new_lockout_level, NOW() + (v_lockout_duration || ' seconds')::INTERVAL, NOW())
    ON CONFLICT (ip_address) DO UPDATE SET
      lockout_level = v_new_lockout_level,
      lockout_until = NOW() + (v_lockout_duration || ' seconds')::INTERVAL,
      updated_at = NOW();

    RETURN QUERY SELECT FALSE, v_lockout_duration, v_new_lockout_level;
    RETURN;
  END IF;

  -- Allowed
  RETURN QUERY SELECT TRUE, 0, 0;
END;
$$ LANGUAGE plpgsql;
```

**5. RPC to record attempt:**
```sql
CREATE OR REPLACE FUNCTION record_access_code_attempt(
  p_prefix TEXT,
  p_ip INET,
  p_success BOOLEAN
) RETURNS VOID AS $$
BEGIN
  INSERT INTO access_code_attempts (prefix, ip_address, success)
  VALUES (p_prefix, p_ip, p_success);

  -- If success, clear lockouts for this prefix
  IF p_success THEN
    DELETE FROM access_code_lockouts WHERE prefix = p_prefix;
  END IF;
END;
$$ LANGUAGE plpgsql;
```

**6. Indexes on access_codes:**
```sql
CREATE INDEX idx_access_codes_user_id ON access_codes(user_id);
CREATE INDEX idx_access_codes_prefix ON access_codes(prefix);
CREATE INDEX idx_access_codes_expires_at ON access_codes(expires_at);
```

**7. RLS policies (service role only for now):**
```sql
ALTER TABLE access_codes ENABLE ROW LEVEL SECURITY;
ALTER TABLE access_code_attempts ENABLE ROW LEVEL SECURITY;
ALTER TABLE access_code_lockouts ENABLE ROW LEVEL SECURITY;

-- Service role can do everything
CREATE POLICY "service_role_access_codes" ON access_codes
  FOR ALL TO service_role USING (true) WITH CHECK (true);

CREATE POLICY "service_role_access_code_attempts" ON access_code_attempts
  FOR ALL TO service_role USING (true) WITH CHECK (true);

CREATE POLICY "service_role_access_code_lockouts" ON access_code_lockouts
  FOR ALL TO service_role USING (true) WITH CHECK (true);
```
  </action>
  <verify>
Run the migration in Supabase SQL editor. Verify:
1. `SELECT * FROM access_codes LIMIT 1;` runs without error
2. `SELECT * FROM access_code_attempts LIMIT 1;` runs without error
3. `SELECT check_access_code_rate_limit('test', '127.0.0.1'::inet);` returns (true, 0, 0)
  </verify>
  <done>All three tables exist, indexes are created, RPC functions work, RLS is enabled</done>
</task>

<task type="auto">
  <name>Task 3: Add Pydantic models for access codes</name>
  <files>apps/api/src/app/models.py</files>
  <action>
Add a new section to models.py after the Agent Checkin Models section:

```python
# ============================================================
# Access Code Models
# ============================================================


class AccessCodeGenerateRequest(BaseModel):
    """Request body for generating an access code."""
    custom_secret: Optional[str] = None  # If provided, use instead of random


class AccessCodeGenerateResponse(BaseModel):
    """Response from generating an access code.

    Note: full_code is returned ONLY on generation. It cannot be retrieved later.
    """
    prefix: str  # 4-char prefix (always visible)
    full_code: str  # prefix-secret (shown once, then only prefix visible)
    expires_at: datetime


class AccessCodeRotateRequest(BaseModel):
    """Request body for rotating an access code secret."""
    custom_secret: Optional[str] = None  # If provided, use instead of random


class AccessCodeRotateResponse(BaseModel):
    """Response from rotating an access code."""
    prefix: str
    full_code: str
    rotated_at: datetime
    expires_at: datetime


class AccessCodeInfoResponse(BaseModel):
    """Access code info (without secret)."""
    prefix: str
    created_at: datetime
    expires_at: datetime
    rotated_at: Optional[datetime] = None


class RoleResponse(BaseModel):
    """Role data in access code validation response."""
    id: str
    name: str
    priority: int
    permission_keys: list[str]


class AccessCodeUserContext(BaseModel):
    """User context returned on successful validation."""
    id: str
    name: Optional[str] = None
    email: str
    user_type: str  # "admin" | "va"
    org_id: str
    is_admin: bool


class AccessCodeValidateRequest(BaseModel):
    """Request body for validating an access code."""
    code: str  # Full code: prefix-secret


class AccessCodeValidateResponse(BaseModel):
    """Response from successful access code validation."""
    access_token: str
    expires_in: int  # seconds
    user: AccessCodeUserContext
    roles: list[RoleResponse]
    effective_permission_keys: list[str]
    rbac_version: str  # ISO timestamp of last permission change


class AccessCodeErrorResponse(BaseModel):
    """Response for failed access code validation."""
    error_code: str  # "INVALID_CODE", "ACCOUNT_DISABLED", "RATE_LIMITED", "CODE_EXPIRED"
    message: str  # User-facing message
    retry_after: Optional[int] = None  # Seconds until retry allowed (for rate limit)
```

Import datetime at top if not already imported. The existing file already has `from datetime import date, datetime` so this should work.
  </action>
  <verify>
Run `python -c "from app.models import AccessCodeValidateResponse; print('OK')"` from apps/api/src directory
  </verify>
  <done>All AccessCode* models import successfully without errors</done>
</task>

</tasks>

<verification>
1. Dependencies: `pip show argon2-cffi slowapi` shows both installed
2. Database: All tables exist and RPC functions work
3. Models: Python import succeeds for all new models
</verification>

<success_criteria>
- argon2-cffi and slowapi are installed and listed in pyproject.toml
- Migration 035_access_codes.sql creates all tables and functions
- All Pydantic models defined and importable
- No runtime errors when importing models
</success_criteria>

<output>
After completion, create `.planning/phases/01-access-code-foundation/01-01-SUMMARY.md`
</output>
