---
phase: 13-worker-status-dashboard-metrics
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - apps/api/src/app/services/parallel_runner.py
  - apps/api/src/app/services/collection.py
autonomous: true

must_haves:
  truths:
    - "Activity events include URL being hit"
    - "Activity events include API parameters (query, price range, node_id, page)"
    - "Activity events include request duration in milliseconds"
    - "Activity events classify error types (rate_limit, timeout, http_error, parse_error)"
    - "Pipeline operations emit activity events (upload, dedupe, insert, update)"
  artifacts:
    - path: "apps/api/src/app/services/parallel_runner.py"
      provides: "Extended ActivityEvent dataclass"
      contains: "url: str | None"
    - path: "apps/api/src/app/services/collection.py"
      provides: "Rich event emission with timing and pipeline events"
      contains: "action=\"uploading\""
  key_links:
    - from: "collection.py process_category"
      to: "ActivityEvent"
      via: "create_activity_event with url, api_params, duration_ms"
      pattern: "url=.*api_params=.*duration_ms="
    - from: "collection.py seller insert"
      to: "ActivityEvent"
      via: "pipeline event emission"
      pattern: "action=\"inserted\""
---

<objective>
Extend backend ActivityEvent with rich metadata and pipeline action types

Purpose: Enable frontend to display full worker transparency (URL, params, timing) and track data pipeline operations
Output: ActivityEvent dataclass with new optional fields, collection.py emitting richer events
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/13-worker-status-dashboard-metrics/13-CONTEXT.md
@.planning/phases/13-worker-status-dashboard-metrics/13-RESEARCH.md
@apps/api/src/app/services/parallel_runner.py
@apps/api/src/app/services/collection.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Extend ActivityEvent Dataclass</name>
  <files>apps/api/src/app/services/parallel_runner.py</files>
  <action>
Extend the ActivityEvent dataclass with new optional fields for full worker transparency:

```python
@dataclass
class ActivityEvent:
    """Activity event for SSE streaming."""
    # Existing fields
    id: str
    timestamp: str
    worker_id: int
    phase: str  # "amazon" or "ebay"
    action: str  # Existing: "fetching", "found", "error", "rate_limited", "complete"
                 # NEW pipeline: "uploading", "deduped", "inserted", "updated"
    category: str | None = None
    product_name: str | None = None
    seller_found: str | None = None
    new_sellers_count: int | None = None
    error_message: str | None = None

    # NEW: Request details (for full transparency)
    url: str | None = None                      # Full URL being hit
    api_params: dict | None = None              # {query, price_min, price_max, node_id, page}

    # NEW: Timing
    duration_ms: int | None = None              # Request duration in milliseconds
    started_at: str | None = None               # ISO timestamp when request began

    # NEW: Retry context
    attempt: int | None = None                  # 1, 2, 3 for retry attempts

    # NEW: Error classification
    error_type: str | None = None               # "rate_limit", "timeout", "http_500", "parse_error"
    error_stage: str | None = None              # "api", "product_extraction", "seller_extraction", "price_parsing"

    # NEW: Pipeline context (for worker_id=0 system events)
    items_count: int | None = None              # Number of items affected
    source_worker_id: int | None = None         # Which worker produced this data
    operation_type: str | None = None           # "product_batch", "seller_dedupe", "seller_insert"
```

The to_dict() method already filters None values, so no changes needed there.

Update create_activity_event helper to accept all new fields via **kwargs (it already does this, just verify).
  </action>
  <verify>
Run: `cd apps/api && python -c "from app.services.parallel_runner import ActivityEvent, create_activity_event; e = create_activity_event(1, 'amazon', 'fetching', url='https://test.com', duration_ms=150, api_params={'node_id': '123'}); print(e.to_dict())"`

Should print dict with url, duration_ms, api_params fields present.
  </verify>
  <done>ActivityEvent dataclass has all new fields: url, api_params, duration_ms, started_at, attempt, error_type, error_stage, items_count, source_worker_id, operation_type</done>
</task>

<task type="auto">
  <name>Task 2: Emit Rich Events and Pipeline Events in collection.py</name>
  <files>apps/api/src/app/services/collection.py</files>
  <action>
Update event emission in collection.py to include rich metadata and add pipeline events.

**1. In process_category (Amazon phase, ~line 1246):**

Before the API call, capture start time:
```python
import time
request_start = time.time()
```

After API call, calculate duration:
```python
duration_ms = int((time.time() - request_start) * 1000)
```

Update the "fetching" event to include api_params:
```python
await runner.emit_activity(create_activity_event(
    worker_id=worker_id,
    phase="amazon",
    action="fetching",
    category=category_name,
    api_params={"node_id": node_id},
    attempt=attempt + 1,
))
```

Update the "found" event to include duration:
```python
await runner.emit_activity(create_activity_event(
    worker_id=worker_id,
    phase="amazon",
    action="found",
    category=category_name,
    new_sellers_count=len(result.products),
    duration_ms=duration_ms,
))
```

Update the "error" event to include error_type:
```python
error_type = "rate_limit" if result.error == "rate_limited" else (
    "timeout" if "timeout" in result.error.lower() else (
        "http_500" if "http_error" in result.error else "api_error"
    )
)
await runner.emit_activity(create_activity_event(
    worker_id=worker_id,
    phase="amazon",
    action="error",
    category=category_name,
    error_message=result.error,
    error_type=error_type,
    error_stage="api",
    duration_ms=duration_ms,
))
```

**2. In process_product (eBay phase, ~line 1605):**

Same pattern - capture timing around each page request.

Update "fetching" event:
```python
await runner.emit_activity(create_activity_event(
    worker_id=worker_id,
    phase="ebay",
    action="fetching",
    category=cat_name,
    product_name=short_title,
    api_params={
        "query": title[:50],  # Truncate for readability
        "price_min": int(price * 0.8),
        "price_max": int(price * 1.2),
        "page": page,
    },
    attempt=1,
))
```

Update "found" event with duration.

**3. Add Pipeline Events (after batch operations):**

After batch product insert (~line 1383):
```python
await runner.emit_activity(create_activity_event(
    worker_id=0,  # System event
    phase="amazon",
    action="uploading",
    items_count=len(products_to_insert),
    operation_type="product_batch",
))
```

After seller deduplication (~line 1724-1744):
```python
await runner.emit_activity(create_activity_event(
    worker_id=0,
    phase="ebay",
    action="deduped",
    items_count=len(duplicates),
    operation_type="seller_dedupe",
))
```

After new seller insert (~line 1760-1768):
```python
await runner.emit_activity(create_activity_event(
    worker_id=0,
    phase="ebay",
    action="inserted",
    items_count=len(new_sellers),
    source_worker_id=worker_id,
    operation_type="seller_insert",
))
```

After existing seller update (~line 1746-1757):
```python
await runner.emit_activity(create_activity_event(
    worker_id=0,
    phase="ebay",
    action="updated",
    items_count=len(existing_to_update),
    operation_type="seller_update",
))
```

Note: The exact line numbers may vary due to prior modifications. Search for the relevant code patterns rather than relying on exact line numbers.
  </action>
  <verify>
1. Run a test collection and observe the backend logs - should show timing information
2. Connect to SSE endpoint and verify events include new fields:
   - Events should have `duration_ms` field
   - Events should have `api_params` field with query/price/page info
   - Pipeline events with `worker_id=0` should appear for batch operations
  </verify>
  <done>
- Amazon phase events include api_params (node_id) and duration_ms
- eBay phase events include api_params (query, price_min, price_max, page) and duration_ms
- Error events include error_type and error_stage classification
- Pipeline events emitted: uploading (products), deduped, inserted, updated (sellers)
  </done>
</task>

</tasks>

<verification>
1. ActivityEvent dataclass compiles without errors
2. create_activity_event works with all new parameters
3. Backend logs show timing information during collection
4. SSE events include new fields when viewed in browser dev tools
</verification>

<success_criteria>
- ActivityEvent has 10 new optional fields for rich metadata
- Collection emits api_params with each request
- Collection emits duration_ms after each API call
- Error events include error_type classification
- Pipeline events (uploading, deduped, inserted, updated) emitted for batch operations
- Backward compatible - existing event structure unchanged
</success_criteria>

<output>
After completion, create `.planning/phases/13-worker-status-dashboard-metrics/13-01-SUMMARY.md`
</output>
